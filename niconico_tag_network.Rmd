---
title: "yukkyuri_tag_network"
author: "Yusuke Fukasawa"
date: "2015年10月19日"
output: html_document
---

```{r,cache=TRUE}
require(niconico)
require(igraph)
# ゆっくりに関連したタグで検索をかける

s1<-getSearch(query = "ゆっくり実況プレイ", size = 100, type = "tag")
s2<-getSearch(query = "ゆっくり実況", size = 100, type = "tag")
s3<-getSearch(query = "ゆっくり", size = 100, type = "tag")
s4<-getSearch(query = "ゆっくり実況プレイpart1リンク", size = 100, type = "tag")
s5<-getSearch(query = "ゆっくりTRPG", size = 100, type = "tag")
s6<-getSearch(query = "ゆっくり解説", size = 100, type = "tag")
s7<-getSearch(query = "ゆっくりロボット物実況", size = 100, type = "tag")
s8<-getSearch(query = "ゆっくり怪談", size = 100, type = "tag")
s9<-getSearch(query = "ゆっくりボイス", size = 100, type = "tag")
s10<-getSearch(query = "ゆっくり実況プレイ最終回リンク", size = 100, type = "tag")
s11<-getSearch(query = "ゆっくり劇場", size = 100, type = "tag")
s12<-getSearch(query = "ゆっくりしていってね！！！", size = 100, type = "tag")
s13<-getSearch(query = "ゆっくり朗読", size = 100, type = "tag")
s14<-getSearch(query = "ゆっくり評価されるべき", size = 100, type = "tag")
s15<-getSearch(query = "多人数ゆっくり実況プレイ", size = 100, type = "tag")
s16<-getSearch(query = "ゆっくり車載", size = 100, type = "tag")
s17<-getSearch(query = "ゆっくりMinecraft", size = 100, type = "tag")
s18<-getSearch(query = "ゆっくりスプラトゥーン", size = 100, type = "tag")
s19<-getSearch(query = "ゆっくりショート怪談リンク", size = 100, type = "tag")
s20<-getSearch(query = "ゆっくり解説Part1リンク", size = 100, type = "tag")
s21<-getSearch(query = "艦娘ゆっくり実況プレイ", size = 100, type = "tag")
s22<-getSearch(query = "ゆっくり旅行", size = 100, type = "tag")
s23<-getSearch(query = "ゆっくりTRPG第一話リンク", size = 100, type = "tag")
s24<-getSearch(query = "ゆっくり実況プレイ単発リンク", size = 100, type = "tag")
s25<-getSearch(query = "ホラーゆっくり実況", size = 100, type = "tag")
s26<-getSearch(query = "本気で歌うゆっくりシリーズ", size = 100, type = "tag")
s27<-getSearch(query = "ホラーゆっくり実況", size = 100, type = "tag")
s28<-getSearch(query = "ゆっくり生活", size = 100, type = "tag")
int<-rbind(s1,s2,s3,s4,s5,s6,s7,s8,s9,s10,s11,s12,s13,s14,s15,s16,s17,s18,s19,s20,s21,s22,s23,s24,s25,s26,s27,s28)
# いらないものはすてる
int<-int[,c(-1,-4,-5,-10,-11)]

# このままだとlistオブジェクトでどうにもならないので、列ごとに適したものに変換する
int$start_time<-as.character(int$start_time)
int$start_time<-as.POSIXlt(int$start_time)
int$comment_counter<-as.numeric(int$comment_counter)
int$length_seconds<-as.numeric(int$length_seconds)
int$view_counter<-as.numeric(int$view_counter)
int$mylist_coutner<-as.numeric(int$mylist_counter)
int$tags<-as.character(int$tags)

# これで各タグの頻度が算出できる
t1<-strsplit(int$tags, " ")
t1<-unlist(t1)
t1<-data.frame(table(t1))
t2<-subset(t1,Freq>=2)


# 唯一存在するタグのみを抽出
taghead<-int$tags
taghead<-data.frame(taghead)
taghead$taghead<-as.character(taghead$taghead)
tags<-strsplit(taghead$taghead, " ")
tags<-data.frame(unlist(tags))
tags<-unique(tags)
names(tags)<-c("tag")

# タグ毎の平均視聴数・コメント数・マイリスト数を算出


# タグ同士の関係を表現する(白目)
```
上記に書いたようなことがしたいのだが、上手くいかぬ。 そんなところに一筋の光が。対角成分が0にならないのは不安だが、こいつで何とかしてみたい。

エクセルで処理したものを読み込むところから
```{r,cache=TRUE}
seed<-read.csv("seed.csv",fileEncoding="cp932")
adjacency <- function(n){
## 出力行列の初期化
mydata <- diag(0,length(colnames(n)))
## 行，列に名前を付ける
colnames(mydata) <- colnames(n)
rownames(mydata) <- colnames(n)
## rは列番号
for(r in 1:length(colnames(n))){
## r行目に，縦方向に合計したものを代入
mydata[r,] <- colSums(
## r列目が1になっている行を対象にして
n[n[,r] == 1,]
)
}
mydata
}

adj<-adjacency(seed)
g <- graph.adjacency(adj,weighted=TRUE)
write.graph(g,"taggraph.gml","gml")
```
で、出来たグラフをGephiでちょこちょこといじりまして。 最初の時点で次数が9以下のノードを削除し、各種統計量を計算してからcsvでノードリストを吐き出させます。 吐き出したノードリストに平均再生回数・コメント数・マイリスト数・動画再生時間・アップ日時の情報を付与。 このとき約1%のノードは文字化けしてしまって対応が取れなくなってしまったので、ノード数11以上のものは数も少なかったので頑張って復旧しましたが、10以下のやつは多かったので、エラーにならないノード(次数同じ)の平均値をとって、標準偏差をいい感じのにして正規分布乱数で値を生成して代替しました。うん。ごめんなさい。

で、今回の目的はタグから見る、ニコニコゆっくり界隈において芽生えつつある文化を探る、というものでした。 ここでは定着した文化はランキングに入ってきやすいという仮定を置いて、ランキングポイント(総合ポイント＝再生数+(コメント数×補正値)+マイリスト数×15)の上位5%を正しい例、下位5%を負例をしてトレーニングセットを構築することにします。

補正値=(再生数+マイリスト数)/(再生数+コメント数+マイリスト数) 本当は広告ポイントもあるんだけど今回は無視。
```{r}
require(e1071)
require(randomForest)
require(ggplot2)
require(knitr)
# 予め作成したノードリストを読み込む
set<-read.csv("taggraph_nodes.csv",fileEncoding = "CP932")
set<-na.omit(set)
#再生数などの情報は既にポイントで反映していると考え削除しておく。計算結果を最終的にsetに貼って出力しGephiでまた使う
set1<-set[,c(-2,-3,-10,-17,-18,-19)]
plus<-subset(set1,set1$Points>2.5*mean(set1$Points))
minus<-subset(set1,set1$Points<0.05*mean(set1$Points))
plus$culture<-as.factor(1)
minus$culture<-as.factor(0)

# チューニング用とテスト用に分ける
plus1<-plus[c(1:47),]
plus2<-plus[c(48:94),]
minus1<-minus[c(1:46),]
minus2<-minus[c(47:92),]
learning<-data.frame(rbind(plus1,minus1))
test<-data.frame(rbind(plus2,minus2))
# 日付型は使えないのでnumericに。あと、Hubは削除。
learning1<-learning[,c(-1,-5,-16)]
learning1$ave_starttime<-as.numeric(learning1$ave_starttime)
learning1$Authority<-as.numeric(learning1$Authority)
test1<-test[,c(-1,-5,-16)]
test1$ave_starttime<-as.numeric(test1$ave_starttime)
test1$Authority<-as.numeric(test1$Authority)
```
```{r}
# 最適なところで重要度を計算したい
tuneRF(learning1[,-14],learning1[,14],doBest=T)
# mtry=2が最適な模様
# 文字化けに気をつけて。。。UTF-8にして日本語を打ち込むと良い模様
importance<-randomForest(culture~.,learning1,mtry=6,importance = TRUE)
knitr::kable(importance(importance))

# どの変数が重要なのかはわかったので、これからSVMによる学習とチューニングを行います
presvm<-svm(culture~.,learning1,cross=8)
summary(presvm)
# デフォルトでは90%前後といったところか
# ここからはチューニング
gammaRange = 10^(-5:5)
costRange = 10^(-2:2)
t <- tune.svm(culture ~ ., data = learning1, gamma=gammaRange, cost=costRange,
              tunecontrol = tune.control(sampling="cross", cross=8))
cat("- best parameters:\n")
cat("gamma =", t$best.parameters$gamma, "; cost =", t$best.parameters$cost, ";\n")
cat("accuracy:", 100 - t$best.performance * 100, "%\n\n")
plot(t, transform.x=log10, transform.y=log10)
```